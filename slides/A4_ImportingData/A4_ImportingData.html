<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Data Wrangling &amp; Exploration with the Tidyverse in R</title>
    <meta charset="utf-8" />
    <meta name="author" content="Johannes Breuer Stefan J√ºnger Thomas Ebel" />
    <meta name="date" content="2019-05-15" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="..\workshop.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Data Wrangling &amp; Exploration with the Tidyverse in R
## Importing Data
### Johannes Breuer<br />Stefan J√ºnger<br />Thomas Ebel
### 2019-05-15

---

layout: true



&lt;div class="my-footer"&gt;
  &lt;div style="float: left;"&gt;&lt;span&gt;Johannes Breuer, Stefan J√ºnger, Thomas Ebel&lt;/span&gt;&lt;/div&gt;
  &lt;div style="float: right;"&gt;&lt;span&gt;GESIS, Mannheim, Germany, 2019-05-15&lt;/span&gt;&lt;/div&gt;
  &lt;div style="text-align: center;"&gt;&lt;span&gt;Importing Data&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

---

# Getting data into `R`

.large[
Thus far, we've already learned that data can be untidy.

This course is also about making them tidy (as well as 'wrangling' and exploring them).

There's one important prerequisite:

.center[**We need data!**]
]

&lt;img src="./pics/import_data.png" width="50%" style="display: block; margin: auto;" /&gt;

---

# Getting data into the `tidyverse`

Whether we want to use our own data or data from others, we need to get data into R.

The `tidyverse` provides some nice tools to do exactly that:

- `readr`  (for 'flat' files, such as CSV)
- `haven`  (for statistical software files, such as SPSS, Stata, and SAS; can also handle labelled data)
- `readxl` (for Excel spreadsheets)

&lt;img src="./pics/hex_all_in_one.png" width="50%" style="display: block; margin: auto;" /&gt;

A key difference between these packages and others is that `tidyverse` import functions already prepare the data for being 'tidied': they are a `tibbles`

---

# A readr example: `read_csv()`

```r
titanic &lt;- read_csv("../../data/titanic/titanic.csv")
```

```
## Parsed with column specification:
## cols(
##   PassengerId = col_double(),
##   Survived = col_double(),
##   Pclass = col_double(),
##   Name = col_character(),
##   Sex = col_character(),
##   Age = col_double(),
##   SibSp = col_double(),
##   Parch = col_double(),
##   Ticket = col_character(),
##   Fare = col_double(),
##   Cabin = col_character(),
##   Embarked = col_character()
## )
```

Note the column specifications. `readr` 'guesses' them based on the first 1000 observations (we will come back to this later).

---

# A readr example: `read_csv()`

```r
titanic
```

```
## # A tibble: 891 x 12
##    PassengerId Survived Pclass Name  Sex     Age SibSp Parch Ticket  Fare
##          &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;
##  1           1        0      3 Brau~ male     22     1     0 A/5 2~  7.25
##  2           2        1      1 Cumi~ fema~    38     1     0 PC 17~ 71.3 
##  3           3        1      3 Heik~ fema~    26     0     0 STON/~  7.92
##  4           4        1      1 Futr~ fema~    35     1     0 113803 53.1 
##  5           5        0      3 Alle~ male     35     0     0 373450  8.05
##  6           6        0      3 Mora~ male     NA     0     0 330877  8.46
##  7           7        0      1 McCa~ male     54     0     0 17463  51.9 
##  8           8        0      3 Pals~ male      2     3     1 349909 21.1 
##  9           9        1      3 John~ fema~    27     0     2 347742 11.1 
## 10          10        1      2 Nass~ fema~    14     1     0 237736 30.1 
## # ... with 881 more rows, and 2 more variables: Cabin &lt;chr&gt;,
## #   Embarked &lt;chr&gt;
```

It's that easy!

---

# A readxl example: `read_excel()`

```r
unicorns &lt;- read_xlsx("../../data/unicorns/observations.xlsx")
```

No output ‚òπÔ∏è

---

# A readxl example: `read_excel()`

```r
unicorns
```

```
## # A tibble: 42 x 3
##    countryname  year   pop
##    &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;
##  1 Austria      1670    85
##  2 Austria      1671    83
##  3 Austria      1674    75
##  4 Austria      1675    82
##  5 Austria      1676    79
##  6 Austria      1677    70
##  7 Austria      1678    81
##  8 Austria      1680    80
##  9 France       1673    70
## 10 France       1674    79
## # ... with 32 more rows
```

---

# A haven example: `read_stata()` 

```r
gesis_panel &lt;- 
  read_stata("../../data/gesis_panel_campusfile/ZA5666_v1-0-0_Stata14.dta")
```

Note: The [`gesis` package](https://github.com/expersso/gesis) allows direct access to the *GESIS* Data Catalogue (DBK) in `R`, given that you have a DBK account.

---

# A haven example: `read_stata()` 

```r
gesis_panel
```

```
## # A tibble: 1,222 x 1,192
##    z000001z z000002z z000003z z000005z a11c019a a11c020a a11c021a a11c022a
##       &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt;
##  1   1.98e8 ZA5666   1-0-0 2~ 10.4232~ 1 [Sehr~ 1 [Sehr~ 1 [Sehr~ 2 [Stim~
##  2   4.36e8 ZA5666   1-0-0 2~ 10.4232~ 1 [Sehr~ 1 [Sehr~ 1 [Sehr~ 2 [Stim~
##  3   8.57e8 ZA5666   1-0-0 2~ 10.4232~ 2 [Eher~ 2 [Eher~ 2 [Eher~ 2 [Stim~
##  4   1.17e8 ZA5666   1-0-0 2~ 10.4232~ 1 [Sehr~ 1 [Sehr~ 1 [Sehr~ 2 [Stim~
##  5   9.43e8 ZA5666   1-0-0 2~ 10.4232~ 1 [Sehr~ 1 [Sehr~ 4 [Eher~ 2 [Stim~
##  6   2.66e8 ZA5666   1-0-0 2~ 10.4232~ 1 [Sehr~ 1 [Sehr~ 1 [Sehr~ 2 [Stim~
##  7   2.76e8 ZA5666   1-0-0 2~ 10.4232~ 1 [Sehr~ 1 [Sehr~ 3 [Wede~ 2 [Stim~
##  8   6.78e8 ZA5666   1-0-0 2~ 10.4232~ 1 [Sehr~ 2 [Eher~ 1 [Sehr~ 3 [Stim~
##  9   4.64e8 ZA5666   1-0-0 2~ 10.4232~ 2 [Eher~ 2 [Eher~ 1 [Sehr~ 3 [Stim~
## 10   4.79e8 ZA5666   1-0-0 2~ 10.4232~ 1 [Sehr~ 1 [Sehr~ 2 [Eher~ 2 [Stim~
## # ... with 1,212 more rows, and 1,184 more variables: a11c023a &lt;dbl+lbl&gt;,
## #   a11c024a &lt;dbl+lbl&gt;, a11c025a &lt;dbl+lbl&gt;, a11c026a &lt;dbl+lbl&gt;,
## #   a11c027a &lt;dbl+lbl&gt;, a11c028a &lt;dbl+lbl&gt;, a11c029a &lt;dbl+lbl&gt;,
## #   a11c030a &lt;dbl+lbl&gt;, a11c031a &lt;dbl+lbl&gt;, a11c032a &lt;dbl+lbl&gt;,
## #   a11c033a &lt;dbl+lbl&gt;, a11c034a &lt;dbl+lbl&gt;, a11c035a &lt;dbl+lbl&gt;,
## #   a11c036a &lt;dbl+lbl&gt;, a11c037a &lt;dbl+lbl&gt;, a11c038a &lt;dbl+lbl&gt;,
## #   a11c039a &lt;dbl+lbl&gt;, a11c040a &lt;dbl+lbl&gt;, a11c041a &lt;dbl+lbl&gt;,
## #   a11c042a &lt;dbl+lbl&gt;, a11c043a &lt;dbl+lbl&gt;, a11c044a &lt;dbl+lbl&gt;,
## #   a11c045a &lt;dbl+lbl&gt;, a11c046a &lt;dbl+lbl&gt;, a11c047a &lt;dbl+lbl&gt;,
## #   a11c048a &lt;dbl+lbl&gt;, a11c049a &lt;dbl+lbl&gt;, a11c050a &lt;dbl+lbl&gt;,
## #   a11c051a &lt;dbl+lbl&gt;, a11c052a &lt;dbl+lbl&gt;, a11c053a &lt;dbl+lbl&gt;,
## #   a11d054a &lt;dbl+lbl&gt;, a11d056z &lt;dbl+lbl&gt;, a11d057d &lt;dbl+lbl&gt;,
## #   a11d072d &lt;dbl+lbl&gt;, a11d074b &lt;dbl+lbl&gt;, a11d075d &lt;dbl+lbl&gt;,
## #   a11d077d &lt;dbl+lbl&gt;, a11d079b &lt;dbl+lbl&gt;, a11d080a &lt;dbl+lbl&gt;,
## #   a11d081a &lt;dbl+lbl&gt;, a11d082b &lt;dbl+lbl&gt;, a11d086b &lt;dbl+lbl&gt;,
## #   a11d089c &lt;dbl+lbl&gt;, a11d090b &lt;dbl+lbl&gt;, a11d092a &lt;dbl+lbl&gt;,
## #   a11d093b &lt;dbl+lbl&gt;, a11d094a &lt;dbl+lbl&gt;, a11d095b &lt;dbl+lbl&gt;,
## #   a11d096b &lt;dbl+lbl&gt;, a11d097c &lt;dbl+lbl&gt;, a11c098a &lt;dbl+lbl&gt;,
## #   a11c099a &lt;dbl+lbl&gt;, a11c100a &lt;dbl+lbl&gt;, a11c101a &lt;dbl+lbl&gt;,
## #   a11c102a &lt;dbl+lbl&gt;, a11c103a &lt;dbl+lbl&gt;, a11c104a &lt;dbl+lbl&gt;,
## #   a11c105a &lt;dbl+lbl&gt;, a11c106a &lt;dbl+lbl&gt;, a11c107a &lt;dbl+lbl&gt;,
## #   a11c108a &lt;dbl+lbl&gt;, a11c109a &lt;dbl+lbl&gt;, a11c110a &lt;dbl+lbl&gt;,
## #   a11c111a &lt;dbl+lbl&gt;, a11c112a &lt;dbl+lbl&gt;, a11c113a &lt;dbl+lbl&gt;,
## #   a11c114a &lt;dbl+lbl&gt;, a11c115a &lt;dbl+lbl&gt;, a11c116a &lt;dbl+lbl&gt;,
## #   a11c117a &lt;dbl+lbl&gt;, a11c118a &lt;dbl+lbl&gt;, a11c119a &lt;dbl+lbl&gt;,
## #   a11c132a &lt;dbl+lbl&gt;, a11a167a &lt;dbl+lbl&gt;, a11a169b &lt;dbl+lbl&gt;,
## #   a12c001a &lt;dbl+lbl&gt;, a12c002a &lt;dbl+lbl&gt;, a12c003a &lt;dbl+lbl&gt;,
## #   a12c004a &lt;dbl+lbl&gt;, a12c005a &lt;dbl+lbl&gt;, a12c006a &lt;dbl+lbl&gt;,
## #   a12c007a &lt;dbl+lbl&gt;, a12c008a &lt;dbl+lbl&gt;, a12c009a &lt;dbl+lbl&gt;,
## #   a12c010a &lt;dbl+lbl&gt;, a12c011a &lt;dbl+lbl&gt;, a12c012a &lt;dbl+lbl&gt;,
## #   a12c013a &lt;dbl+lbl&gt;, a12c014a &lt;dbl+lbl&gt;, a12c015a &lt;dbl+lbl&gt;,
## #   a12c016a &lt;dbl+lbl&gt;, a12c017a &lt;dbl+lbl&gt;, a12c018a &lt;dbl+lbl&gt;,
## #   a12c019a &lt;dbl+lbl&gt;, a12c020a &lt;dbl+lbl&gt;, a12d021b &lt;dbl+lbl&gt;,
## #   a12c022b &lt;dbl+lbl&gt;, a12c023a &lt;dbl+lbl&gt;, a12c025a &lt;dbl+lbl&gt;, ...
```

---

# `read_stata()`'s sister: `read_spss()`

Indeed, there's also the function `read_spss()` to import SPSS files.

It also provides capabilities to handle SPSS-defined missing values by setting the option `user_na = TRUE` (default is `FALSE`).

The [`sjlabelled` package](https://cran.r-project.org/web/packages/sjlabelled/index.html) can also be used to choose a more elaborated approach for missing values: https://cran.r-project.org/web/packages/sjlabelled/vignettes/intro_sjlabelled.html

---

# There's more

These were just some very first examples of applying functions from each package. They comprise even more functions for different data types.

- readr
  - `read_csv()`
  - `read_tsv()`
  - `read_delim()`
  - `read_fwf()`
  - `read_table()`
  - `read_log()`
- haven
  - `read_sas()`
  - `read_spss()`
  - `read_stata()`

Not to mention all the helper functions and options. For example, we can define the cells to read from an Excel file by specifying the option `range = "C1:E4"` in
`read_excel()`


---

# Data specification

- characters
  - indicated by `&lt;chr&gt;`
  - specified by `col_character()`
- integers
  - indicated by `&lt;int&gt;`
  - specified by `col_integer()`
- doubles
  - indicated by `&lt;dbl&gt;`
  - specified by `col_double()`
- factors
  - indicated by `&lt;fct&gt;`
  - specified by `col_factor()`
- logical
  - indicated by `&lt;lgl&gt;`
  - specified by `col_logical()`
  
.center[**There's more, but we'll leave it at that for now.**]

---

# Changing variable types

As mentioned before, `read_csv` 'guesses' the variable types by scanning the first 1000 observations. NB: **This can go wrong!**

Luckily, we can change the variable type...

- before/while loading the data

- and after loading the data

---

# While loading the data in `read_csv`


```r
titanic &lt;-
  read_csv(
    "../../data/titanic/titanic.csv",
    col_types = cols(
      PassengerId = col_double(),
      Survived = col_double(),
      Pclass = col_double(),
      Name = col_character(),
      Sex = col_character(),
      Age = col_double(),
      SibSp = col_double(),
      Parch = col_double(),
      Ticket = col_character(),
      Fare = col_double(),
      Cabin = col_character(),
      Embarked = col_character()
    )
  )
```

---

# While loading the data in `read_csv`


```r
titanic
```

```
## # A tibble: 891 x 12
##    PassengerId Survived Pclass Name  Sex     Age SibSp Parch Ticket  Fare
##          &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;
##  1           1        0      3 Brau~ male     22     1     0 A/5 2~  7.25
##  2           2        1      1 Cumi~ fema~    38     1     0 PC 17~ 71.3 
##  3           3        1      3 Heik~ fema~    26     0     0 STON/~  7.92
##  4           4        1      1 Futr~ fema~    35     1     0 113803 53.1 
##  5           5        0      3 Alle~ male     35     0     0 373450  8.05
##  6           6        0      3 Mora~ male     NA     0     0 330877  8.46
##  7           7        0      1 McCa~ male     54     0     0 17463  51.9 
##  8           8        0      3 Pals~ male      2     3     1 349909 21.1 
##  9           9        1      3 John~ fema~    27     0     2 347742 11.1 
## 10          10        1      2 Nass~ fema~    14     1     0 237736 30.1 
## # ... with 881 more rows, and 2 more variables: Cabin &lt;chr&gt;,
## #   Embarked &lt;chr&gt;
```

---

# While loading the data in `read_csv`


```r
titanic &lt;-
  read_csv(
    "../../data/titanic/titanic.csv",
    col_types = cols(
      PassengerId = col_double(),
      Survived = col_double(),
      Pclass = col_double(),
      Name = col_character(),
      Sex = col_factor(), # This one changed!
      Age = col_double(),
      SibSp = col_double(),
      Parch = col_double(),
      Ticket = col_character(),
      Fare = col_double(),
      Cabin = col_character(),
      Embarked = col_character()
    )
  )
```

---

# While loading the data in `read_csv`


```r
titanic
```

```
## # A tibble: 891 x 12
##    PassengerId Survived Pclass Name  Sex     Age SibSp Parch Ticket  Fare
##          &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;
##  1           1        0      3 Brau~ male     22     1     0 A/5 2~  7.25
##  2           2        1      1 Cumi~ fema~    38     1     0 PC 17~ 71.3 
##  3           3        1      3 Heik~ fema~    26     0     0 STON/~  7.92
##  4           4        1      1 Futr~ fema~    35     1     0 113803 53.1 
##  5           5        0      3 Alle~ male     35     0     0 373450  8.05
##  6           6        0      3 Mora~ male     NA     0     0 330877  8.46
##  7           7        0      1 McCa~ male     54     0     0 17463  51.9 
##  8           8        0      3 Pals~ male      2     3     1 349909 21.1 
##  9           9        1      3 John~ fema~    27     0     2 347742 11.1 
## 10          10        1      2 Nass~ fema~    14     1     0 237736 30.1 
## # ... with 881 more rows, and 2 more variables: Cabin &lt;chr&gt;,
## #   Embarked &lt;chr&gt;
```

---

# After loading the data


```r
titanic &lt;- read_csv("../../data/titanic/titanic.csv")
```

```
## Parsed with column specification:
## cols(
##   PassengerId = col_double(),
##   Survived = col_double(),
##   Pclass = col_double(),
##   Name = col_character(),
##   Sex = col_character(),
##   Age = col_double(),
##   SibSp = col_double(),
##   Parch = col_double(),
##   Ticket = col_character(),
##   Fare = col_double(),
##   Cabin = col_character(),
##   Embarked = col_character()
## )
```

---

# After loading the data


```r
titanic &lt;-
* type_convert(
    titanic,
    col_types = cols(
      PassengerId = col_double(),
      Survived = col_double(),
      Pclass = col_double(),
      Name = col_character(),
      Sex = col_factor(),
      Age = col_double(),
      SibSp = col_double(),
      Parch = col_double(),
      Ticket = col_character(),
      Fare = col_double(),
      Cabin = col_character(),
      Embarked = col_character()
    )
  )
```

---

# Exporting data

Sometimes our data have to leave the `tidyverse` (or even `R`), for example, if we....

- share data with colleagues who do not use `R`
- want to continue where we left off
  - particularly, if data wrangling took a long time
  
For such purposes we also need a way to export our data.

All of the packages we have discussed in this session also have designated functions for that.

&lt;img src="./pics/export_data.png" width="50%" style="display: block; margin: auto;" /&gt;

---

# Examples: CSV and Stata files


```r
write_csv(titanic, "titanic_own.csv")
```


```r
write_dta(titanic, "titanic_own.dta")
```

Proof that they have been exported:

```r
list.files() 
```

```
## [1] "A4_ImportingData.html" "A4_ImportingData.Rmd"  "libs"                 
## [4] "pics"                  "titanic_own.csv"       "titanic_own.dta"
```

---

# Additional packages

The great benefit of `tidyverse` import functions is the import of the data as tibbles: the data are potentially tidier.

Several other non-tidyverse packages provide similar benefits as they make use of this universal data format:
- [`sf`](https://github.com/r-spatial/sf) for geospatial data

- [`sjlabelled`](https://cran.r-project.org/web/packages/sjlabelled/index.html) to work with labelled data, e.g., from SPSS or Stata

---

# Other packages for data import

- `base` R

- the [`foreign` package](https://cran.r-project.org/web/packages/foreign/index.html) for SPSS and Stata files

- [`data.table`](https://cran.r-project.org/web/packages/data.table/index.html) or [`fst`](https://www.fstpackage.org/) for large datasets

- [`jsonlite`](https://cran.r-project.org/web/packages/jsonlite/index.html) for json files

- [`datapasta`](https://github.com/MilesMcBain/datapasta) for copying and pasting data into tribbles (e.g., from websites, Excel or Word files)

---

class: center, middle

# [Exercise](https://jobreu.github.io/tidyverse-workshop-gesis-2019/exercises/A4_ImportingData_exercises_question.html) time üèãÔ∏è‚Äç‚ôÄÔ∏èüí™üèÉüö¥

## [Solutions](https://jobreu.github.io/tidyverse-workshop-gesis-2019/solutions/A4_ImportingData_exercises_solution.html)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
